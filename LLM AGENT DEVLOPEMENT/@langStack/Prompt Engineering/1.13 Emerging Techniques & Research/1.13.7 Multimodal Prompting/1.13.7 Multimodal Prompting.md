# 1.13.7 Multimodal Prompting

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.13.7.1 Image-to-Text]]** | Captioning | "Describe this image in detail" | Translating visual information into a text format that downstream tools can use. |
| **[[1.13.7.2 Text-to-Image (Stable Diffusion)]]** | Generation | Midjourney, DALL-E, negative prompts | Writing the specific "spells" (prompts) that summon images from noise. |
| **[[1.13.7.3 Audio Prompting]]** | Sound | "Speak like a pirate", TTS control | Prompting text-to-speech models to control emotion, prosody, and speed. |
| **[[1.13.7.4 Video Understanding]]** | Temporal | "What happens at 0:30?", event detection | Asking questions about actions that unfold over time in a video clip. |
| **[[1.13.7.5 Cross-Modal Reasoning]]** | Logic | "Does the audio match the subtitles?" | using the model to check consistency between two different sensory inputs. |
| **[[1.13.7.6 Interleaved Input]]** | Format | Image + Text + Image, storytelling | constructing a prompt that weaves text and images together into a coherent narrative. |
| **[[1.13.7.7 Spatial Prompts]]** | Layout | "Put the cat in the top left", composition | Controlling the specific location of generated objects in an image. |
| **[[1.13.7.8 Negative Prompts (Images)]]** | Removal | "Ugly, blurry, low res, extra fingers" | Telling the model explicitly what you *don't* want to see. |
| **[[1.13.7.9 Multimodal Context]]** | Memory | "Remember the shirt I showed you?", continuity | referencing an image uploaded 5 turns ago in the conversation. |
| **[[1.13.7.10 Unified Models (Gemini/GPT-4V)]]** | Architecture | Native multimodal vs glued together | Understanding if the model truly "sees" or if it just uses an OCR tool. |

This table represents a **complete guide to Multimodal Prompting**, beyond the keyboard.
