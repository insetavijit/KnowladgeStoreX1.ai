# Context Window & Memory

**Core Definition:** The **Context Window** is the maximum amount of text (prompt + conversation history + answer) an LLM can keep in its "working memory" at one time. If text leaves this window, the model instantly forgets it.

## How It Works

Models do not have long-term memory hardcoded. They only "know" what is currently present in their input prompt (the context).

*   **Analogy:** The context window is like the RAM of your computer or the "whiteboard" in a meeting. Once the whiteboard is full, you must erase something to write more.

## Context Length Evolution

The size of this window is a fixed architectural limit defined during training.

| Model Era | Typical Context Size | Approx. Word Count |
| :--- | :--- | :--- |
| **GPT-3 (2020)** | 2k - 4k tokens | 1.5k - 3k words |
| **GPT-4 (2023)** | 8k - 32k tokens | 6k - 24k words |
| **GPT-4 Turbo / Claude 3** | 128k - 200k tokens | 95k - 150k words |
| **Gemini 1.5 Pro** | 1M - 2M+ tokens | 750k - 1.5M words |

## Sliding Window & Truncation

When a conversation exceeds the limit, systems must handle the overflow.
1.  **Truncation:** Simply cutting off the oldest messages. The model "forgets" the start of the chat.
2.  **Sliding Window:** Maintaining a moving window of the last *N* tokens.
3.  **Summarization:** Compressing old messages into a summary and keeping that in context.

## Attention Sink & "Lost in the Middle"

Even with massive windows (e.g., 200k), models aren't perfect.
*   **Recency Bias:** Models pay most attention to the very end of the prompt (the immediate question).
*   **Primacy Bias:** Models also pay attention to the very beginning (system instructions).
*   **Lost in the Middle:** Information buried in the middle of a massive context window is often retrieved less accurately than information at the start or end.

## Quick Summaries

**30-second version:**  
The Context Window is the hard limit on "live memory." Every word of history you want the model to use must be re-sent with every new request. As context grows, costs increase and "attention" to specific details can dilute, leading to the "lost in the middle" phenomenon.

**One-line recall:**  
**Context is a fixed-size buffer; if it scrolls off the top, the model forgets it exists.**

---

**Section:** **1.1.1.7 Context Window & Memory**  
**Focus:** Working memory  
**Last updated:** December 2025

---
