# Instruction Placement

**Core definition:** **Instruction Placement** refers to *where* in the prompt (beginning, middle, or end) the core directive is located, significantly impacting the model's ability to follow it due to attention mechanisms.

**Key idea:**

-   **Primacy Effect:** Humans and models tend to remember the *first* thing they read.
-   **Recency Effect:** Models have a strong bias towards the *last* thing they read.
-   **"Lost in the Middle":** Instructions buried in the center of a long context window are often ignored or "forgotten."

## Why It Matters

You can write the perfect instruction, but if you place it in the "dead zone" of a long prompt (surrounded by 10k tokens of text), the model may hallucinate or default to generic behavior. Strategic placement ensures the model *attends* to your command.

## Essential Functions

**1. The "Sandwich" Strategy:**
Placing the instruction at *both* the beginning (System/Start of User) and the end (End of User) of the prompt.
*   *Start:* "Summarize the text below."
*   *Middle:* [Long Text]
*   *End:* "Again, summarize the text above in 3 bullets."

**2. Instruction Anchoring:**
Forcing the instruction to be the very last token before generation begins. This leverages the Recency Effect to maximize adherence.

**3. Separation from Context:**
Ensuring instructions aren't visually merged with the data (using delimiters) so the model sees them as distinct commands.

## Anatomy of Optimal Placement

**Scenario: Processing a Long Document**

```text
[SYSTEM]
You are a helpful summarizer.

[USER]
# INSTRUCTION (Primacy) -> Good for setting the stage
Please summarize the following financial report. Focus on net revenue.

# CONTEXT (Middle) -> The "Data"
... [5,000 words of text] ...

# INSTRUCTION REMINDER (Recency) -> CRITICAL
Based on the report above, confirm the net revenue figures.
```

## Attention Bias in LLMs

| Placement | Adherence Probability | Best For |
| :--- | :--- | :--- |
| **Beginning** | High | Persona, Global constraints, Format (System Message). |
| **Middle** | Low - Medium | specific Data, Context, Reference material. |
| **End** | **Highest** | Immediate tasks, Output triggers, "Call to action". |

## Common Patterns

**1. The "Post-Context" Command**
Always repeat the specific question *after* the provided context.
*   *Bad:* "Who is the CEO? Here is the document: [Doc]"
*   *Good:* "Here is the document: [Doc]. Based on this, who is the CEO?"

**2. The Closeness Rule**
Keep the instruction as close as possible to the point of generation.

**3. Negative Constraint Placement**
Negative constraints ("Do not...") are often weaker in the middle. Place them in the System Message or at the very end for maximum effect.

## Quick Summaries

**30-second version:**
LLMs process text sequentially but have uneven "attention" spans. They pay the most attention to the very beginning and the very end of the prompt context. Instructions placed in the middle of a large block of text are prone to being ignored. To ensure your commands are followed, place them at the start (System) and repeat the core action at the very end (User), effectively sandwiching the data.

**One-line recall:**
**Instruction Placement = Start strong + End strong + Avoid the messy middle.**

---

**Section:** **1.1.2.4 Instruction Placement**
**Focus:** Attention management
**Last updated:** December 2025

---
