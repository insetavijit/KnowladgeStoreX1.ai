# Multi-Message Chat Structure

**Core definition:** **Multi-Message Chat Structure** (or ChatML) refers to the formatted list of messages (System, User, Assistant) that represents the entire conversation history passed to the model for each new turn.

**Key idea:**

-   **Statelessness:** LLMs have no memory. They re-read the *entire* conversation history (as a list of messages) to generate the next response.
-   **Roles:** Distinct roles (System, User, Assistant) structure the conversation flow.
-   **Conversation Management:** Truncating or summarizing old messages to fit the context window.

## Why It Matters

A single prompt is simple. But building a chatbot requires managing a growing list of messages. Understanding how to structure, order, and prune this list is essential for maintaining context (memory) without exceeding token limits or confusing the model.

## The Chat Object Structure

Modern APIs (OpenAI, Anthropic) expect a specific list format:

```json
[
  {"role": "system", "content": "You are a helpful assistant."},
  {"role": "user", "content": "Hi, my name is Alice."},
  {"role": "assistant", "content": "Hello Alice! How can I help?"},
  {"role": "user", "content": "What is my name?"}
]
```
*The model reads all of this to output: "Your name is Alice."*

## Essential Components

**1. The History Chain:**
The chronological sequence of `{role, content}` pairs.

**2. The Current Turn:**
The final `user` message that triggers the new response.

**3. The Sliding Window:**
The mechanism for removing the oldest messages (except the System Prompt) when the list gets too long.

## Anatomy of a Conversation

| Position | Role | Purpose | Persistence |
| :--- | :--- | :--- | :--- |
| **0** | **System** | Global Rules | **Always Kept** (Pinned) |
| **1...N-1** | **History** | Context / Memory | **Managed** (Sliding Window / Summary) |
| **N** | **User** | Current Task | **New Input** |

## Best Practices

**1. Pin the System Prompt**
Never truncate the System Message. It must always be present (usually at index 0) or the model loses its persona.

**2. Use "Assistant" for Pre-filling**
(See 1.1.2.3) You can manually add an `assistant` message at the very end to force a specific start to the response.

**3. Format Consistency**
Ensure the "conversation style" (e.g., short Q&A vs long paragraphs) remains consistent in the history to bias the model towards maintaining that style (style matching).

## Common Patterns

**1. Summary Injection**
When history gets too long, summarize the first 10 turns into a new "System" note:
*   `System: Context: User is named Alice, asked about Python previously.`

**2. The One-Shot Session**
Creating a "fake" chat history to teach the model how to behave before the *real* user even types a word.

## Quick Summaries

**30-second version:**
Multi-message structure is how we give "memory" to a stateless AI. We pass a structured list of dictionaries—representing the past conversation—along with the new query. Managing this list (keeping the System prompt, pruning old messages to save tokens, and formatting the history) is the core engineering challenge of building conversational agents.

**One-line recall:**
**Chat Structure = List of {Role, Content} objects representing state.**

---

**Section:** **1.1.2.10 Multi-Message Chat Structure**
**Focus:** Conversation Management
**Last updated:** December 2025

---
