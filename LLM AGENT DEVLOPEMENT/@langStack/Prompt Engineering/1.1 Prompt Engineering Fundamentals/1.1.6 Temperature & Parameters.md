# 1.1.6 Temperature & Parameters

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.1.6.1 Temperature Basics]]** | Sampling randomness | Entropy, distribution flattening, creativity vs logic dial | Temperature controls the "creativity" by flattening or sharpening the probability distribution of next tokens. |
| **[[1.1.6.2 Top-P (Nucleus Sampling)]]** | Probability mass | Cumulative probability, dynamic cutoff, tail truncation | Top-P restricts choices to the smallest set of tokens whose cumulative probability exceeds P, discarding wild outliers. |
| **[[1.1.6.3 Top-K Sampling]]** | Hard cutoff | Fixed candidate count, beam search alternative, rigid limits | Top-K strictly limits the model to choosing from the top K most likely next tokens. |
| **[[1.1.6.4 Frequency Penalty]]** | Repetition control | Verbatim repetition, loop prevention, penalizing used tokens | Frequency penalty discourages the model from repeating the exact same lines verbatim. |
| **[[1.1.6.5 Presence Penalty]]** | Topic switching | Concept repetition, encouraging novelty, moving story forward | Presence penalty discourages repeating the same topics, forcing the model to introduce new concepts. |
| **[[1.1.6.6 Stop Sequences]]** | Trailing control | Custom delimiters, early termination, preventing hallucinations | Stop sequences force the model to immediately stop generating upon string match, essential for structured control. |
| **[[1.1.6.7 Determinism vs Creativity]]** | Configuration profiles | Seed setting, temperature 0, greedy decoding | Setting temperature to 0 maximizes determinism for logic tasks, while higher values aid brainstorming. |
| **[[1.1.6.8 Max Tokens & Output Length]]** | Budgeting | Hard limits, cost control, verbosity constraints | Limiting max tokens prevents runaway generation and manages API costs and latency. |
| **[[1.1.6.9 Logit Bias]]** | Vocabulary forcing | Token banning, preferential boosting, surgical vocabulary control | Logit bias effectively forces or bans specific tokens from appearing in the output. |
| **[[1.1.6.10 Learning Rate & Reproducibility]]** | System stability | Seed parameter, opaque backend variance, caching effects | Even with fixed parameters, GPU non-determinism can cause slight variations; seeds help mitigate this. |

This table represents a **complete guide to Model Parameters**, giving developers fine-grained control over the "mind" of the LLM.
