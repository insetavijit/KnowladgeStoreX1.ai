# Step-by-Step Decomposition

**Core definition:** **Decomposition** is the technique of breaking a complex, multi-faceted task into a linear sequence of smaller, easier-to-solve sub-steps.

**Key idea:**
-   **Chain of Thought (CoT):** Asking the model to "think step-by-step" triggers reasoning capabilities that zero-shot prompts miss.
-   **Sequential Processing:** LLMs generate text linearly. If step 2 depends on step 1, you must force the model to solve step 1 *before* it starts writing step 2.
-   **Error Isolation:** If the model fails at step 3, it's easier to debug than a monolithic failure.

## Why It Matters

Complex problems (math, logic, multi-stage coding) often fail in zero-shot mode because the model tries to jump straight to the answer. Decomposition forces the model to show its work, reducing hallucinations and logical leaps. It turns "Magic" into "Method."

## Essential Utilities

**1. The Numbered List:**
Explicitly listing the steps the model must take.
1. Read the text.
2. Extract entities.
3. Categorize them.

**2. The CoT Trigger:**
"Let's think step by step." (The most famous prompt hack).

**3. The "Scratchpad":**
"Use a `<scratchpad>` block to work out your reasoning before giving the final answer."

## Anatomy of Decomposition

**Monolithic Prompt (Fail):**
> "Read this financial report and tell me if the company is a good investment."
> *(Model hallucinates a generic 'Yes' or 'No').*

**Decomposed Prompt (Success):**
> "Analyze this financial report following these steps:
> 1. **Revenue Check:** Has revenue grown year-over-year?
> 2. **Debt Check:** Is the debt-to-equity ratio under 2.0?
> 3. **Risk Check:** Are there any lawsuits mentioned?
> 4. **Conclusion:** Based *only* on the 3 checks above, is it a good investment?"

## Common Patterns

**1. The Pipeline Pattern**
"Step 1: [Action]. Step 2: [Action]. Output: [Result]."

**2. The Self-Correction Step**
"Step 4: Review your answer from Step 3. If there are errors, fix them."

**3. The "Plan-Solve" Pattern**
"First, create a plan to solve this. Then, execute the plan."

## Quick Summaries

**30-second version:**
If a task is too big to eat in one bite, cut it up. Decomposition is about spoon-feeding the logic to the model. Instead of asking for a complex outcome immediately, you ask for a series of simple outcomes that lead to the complex one. This aligns perfectly with the autoregressive (next-token) nature of LLMs, where every generated token becomes context for the next one.

**One-line recall:**
**Decomposition = Divide and Conquer (Chain of Thought).**

---

**Section:** **1.1.3.8 Step-by-Step Decomposition**
**Focus:** Process Design
**Last updated:** December 2025

---
