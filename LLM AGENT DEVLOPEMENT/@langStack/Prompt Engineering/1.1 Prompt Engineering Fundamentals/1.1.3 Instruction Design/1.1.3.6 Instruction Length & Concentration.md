# Instruction Length & Concentration

**Core definition:** **Instruction Length** refers to the token count of the prompt. **Concentration** (or density) refers to the ratio of distinct instructions to total words.

**Key idea:**
-   **Cognitive Load:** Models, like humans, have a limit to how many competing instructions they can hold in "working memory" per inference pass.
-   **Dilution:** Burying a key instruction in 5 paragraphs of backstory often leads to it being ignored ("Lost in the Middle" phenomenon).
-   **Focus:** Shorter, denser prompts often outperform long, rambling ones for complex logic.

## Why It Matters

There is a myth that "more context is always better." In reality, irrelevant context acts as noise. If you give a model 20 instructions in one prompt, the adherence rate for instruction #17 drops significantly. Managing length and concentration is about efficient communication.

## Essential Utilities

**1. The "Trim" Technique:**
Ruthlessly deleting adjectives, adverbs, and polite conversational filler.
*   *Before:* "I would really appreciate it if you could please kindly take a look at..."
*   *After:* "Analyze..."

**2. Splitting (Chaining):**
If a prompt has >5 complex steps, break it into 2 separate prompts (Prompt Chaining).

**3. Reference Separation:**
Moving large blocks of text to a clearly delimited "Context" section so the "Instruction" section remains short and punchy.

## Anatomy of Concentration

**Diluted Prompt (Low Adherence):**
> "Hi GPT! So I'm working on this project dealing with biology and I need you to write a summary. It should be short. Also, make sure you don't use big words because my audience is students. Oh, and include a quiz at the end."

**Concentrated Prompt (High Adherence):**
> "Write a biology summary.
> **Constraints:**
> 1. Length: Under 100 words.
> 2. Audience: 8th-grade students (simple vocabulary).
> 3. Add: A 3-question quiz at the end."

## The "7 ± 2" Rule for LLMs

While LLMs track thousands of tokens, their "instruction following" attention behaves similarly to Miller's Law (humans can hold 7±2 objects in memory).
*   **Best Practice:** Limit a single prompt to **5-7 distinct constraints/instructions**.
*   **Beyond 7:** Reliability drops; use chaining.

## Quick Summaries

**30-second version:**
Don't ramble. Every extra word in a prompt that isn't an instruction or necessary context is a distraction. "Instruction Concentration" is the practice of keeping your commands dense and separate from the data. If your prompt looks like a novel, the model will likely skim it. If it looks like a checklist, the model will follow it.

**One-line recall:**
**Conciseness = Control (Remove the fluff).**

---

**Section:** **1.1.3.6 Instruction Length & Concentration**
**Focus:** Cognitive Load
**Last updated:** December 2025

---
