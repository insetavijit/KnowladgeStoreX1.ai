# 1.3.6 Metacognitive Instructions

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.3.6.1 Self-Reflection Steps]]** | Internal audit | "Review your answer", retrospective analysis, error checking | Asking the model to reflect *after* generating (or before) helps catch obvious mistakes. |
| **[[1.3.6.2 Confidence Scoring]]** | Reliability metric | "Rate your confidence 1-10", probability calibration | Forcing a confidence score can reveal when the model is hallucinating or unsure of its own facts. |
| **[[1.3.6.3 "Check Your Work"]]** | Verification | Step-by-step verification, reverse calculation, sanity check | A simple instruction to "double check" can fix math or logic errors that occurred in the first pass. |
| **[[1.3.6.4 Uncertainty Quantification]]** | Ambiguity handling | "List unknowns", "What information is missing?", known unknowns | Identifying what isn't known is often more valuable than stating what is known. |
| **[[1.3.6.5 Reasoning Trace Explanation]]** | Transparency | "Explain why", justification, decision boundaries | Requiring an explanation of *why* a decision was made makes the output interpretable and debuggable. |
| **[[1.3.6.6 Identifying Assumptions]]** | Logical rigor | Implicit vs explicit, cultural assumptions, axiom check | Exposing hidden assumptions prevents the model from answering based on faulty premises. |
| **[[1.3.6.7 Error Detection & Correction]]** | Auto-fix | "Find the bugs", "Correct the grammar", self-repair | Models are often better at finding errors in their own output than generating perfect output on the first try. |
| **[[1.3.6.8 Planning Before Writing]]** | Outline generation | "Create an outline first", structural planning | Forcing a planning phase reduces "writing on the fly" errors and improves structural coherence. |
| **[[1.3.6.9 Self-Critique Loops]]** | Iterative improvement | "Critique then rewrite", feedback loop, refinement | A generate-critique-rewrite loop (Reflexion) is one of the most powerful patterns for high-quality output. |
| **[[1.3.6.10 Stop & Ask Criteria]]** | Guardrails | "Stop if...", "Ask for clarification if...", safety brakes | Defining when *not* to answer is a critical metacognitive skill for safe agents. |

This table represents a **complete guide to Metacognitive Instructions**, teaching the model to think about its own thinking.
