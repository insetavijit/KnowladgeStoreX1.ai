# 1.5.1 Token Budget Management

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.5.1.1 Counting Tokens (Tiktoken)]]** | Measurement | BPE counting, cl100k_base, encoding/decoding | You cannot manage what you cannot measure; accurate token counting is step zero. |
| **[[1.5.1.2 Input vs Output Limits]]** | Constraints | Context length vs Completion limit, shared vs separate | Understanding that input (prompt) and output (completion) tokens often share the same total budget. |
| **[[1.5.1.3 Cost Optimization]]** | Economics | Price per 1k tokens, prompt caching, batch savings | optimizing token usage isn't just about fitting in memory; it's about controlling the API bill. |
| **[[1.5.1.4 Budget Allocation Strategies]]** | Planning | "System: 10%", "History: 40%", "RAG: 50%" | Proactively defining how much space each component (instructions, history, data) gets prevents collisions. |
| **[[1.5.1.5 Handling Overflow]]** | Errors | Truncation strategies, error catching, graceful degradation | When the limit is hit, the system must fail gracefully (e.g., dropping oldest messages) rather than crashing. |
| **[[1.5.1.6 Padding & Truncation]]** | Formatting | Pre-padding vs Post-truncation, loss of instruction | Choosing *where* to cut (start vs end) determines whether you lose the instructions or the context. |
| **[[1.5.1.7 Efficiency Metrics]]** | KPIs | Tokens per turn, information density ratio | Tracking how many tokens are required to achieve a unit of useful work. |
| **[[1.5.1.8 Token Density]]** | Compression | concise language, removing stopwords, serialization | increasing the amount of semantic meaning per token (e.g., "Jan" vs "January"). |
| **[[1.5.1.9 Monitoring Usage]]** | Observability | Dashboards, usage tracking, cost alerts | Real-time monitoring of token consumption allows for spotting runaway loops or inefficient prompts. |
| **[[1.5.1.10 Model-Specific Limits]]** | Specs | GPT-4 (128k), Claude (200k), Llama 2 (4k) | Designing prompts that adapt to the widely varying limits of different models. |

This table represents a **complete guide to Token Budget Management**, the accounting of the AI world.
