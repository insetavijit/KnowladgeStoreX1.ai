# 1.7.2 Bias Mitigation

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.7.2.1 Stereotype Awareness]]** | Recognition | Implicit association, training data bias, common tropes | Acknowledging that models trained on the internet will default to internet stereotypes. |
| **[[1.7.2.2 Debiasing Prompts]]** | Intervention | "Provide a diverse list", "Avoid gendered assumptions" | Explicitly instructing the model to counteract its training bias in the system prompt. |
| **[[1.7.2.3 Diverse Representation]]** | Output shaping | Demographically balanced examples, name variation | Ensuring generated personas or stories include a mix of names, genders, and backgrounds. |
| **[[1.7.2.4 Gender Neutrality]]** | Language | "They/Them", "Firefighter" vs "Fireman", avoiding assumptions | Defaulting to neutral terms unless gender is relevant to the context. |
| **[[1.7.2.5 Cultural Sensitivity]]** | Localization | Western-centrism, cultural relativism, respectful tone | Realizing that "standard etiquette" usually means "American etiquette" and adjusting for global users. |
| **[[1.7.2.6 Historical Bias context]]** | Nuance | "In the 1800s...", distinguishing fact from endorsement | Discussing historical biases factually without perpetuating them or judging them by modern standards (unless asked). |
| **[[1.7.2.7 Fairness Metrics]]** | Evaluation | Demographic parity, equal opportunity, disparate impact | Measuring whether the model treats "Group A" and "Group B" simply for the same task. |
| **[[1.7.2.8 Counter-Narrative Generation]]** | Balancing | "Tell the other side", highlighting underrepresented views | Actively prompting for perspectives that are statistically rare in the training data. |
| **[[1.7.2.9 Inclusive Language]]** | Style | Person-first language, avoiding ableism, modern terminology | Using current, respectful terminology for disabilities and marginalized groups. |
| **[[1.7.2.10 Blind Evaluation]]** | Testing | Anonymized prompts, removing demographic markers | Testing the model's response quality without revealing the user's identity to check for bias. |

This table represents a **complete guide to Bias Mitigation**, trying to make the AI better than its data.
