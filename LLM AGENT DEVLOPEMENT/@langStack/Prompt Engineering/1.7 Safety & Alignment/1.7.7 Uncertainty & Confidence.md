# 1.7.7 Uncertainty & Confidence

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.7.7.1 Expressing Doubt]]** | Honesty | "I am not sure", "It is possible that..." | Training the model to use language that reflects its internal uncertainty state. |
| **[[1.7.7.2 Confidence Scores]]** | Metrics | Logprobs, percentage confidence, explicit rating | Asking "On a scale of 0-100, how certain are you?" allows for filtering low-quality answers. |
| **[[1.7.7.3 "I Don't Know" Training]]** | Behavior | Refusal to hallucinate, admitting ignorance | It is better for a model to say "I don't know" than to invent a plausible-sounding lie. |
| **[[1.7.7.4 Calibration]]** | Accuracy | "Predicted confidence = Actual accuracy" | A well-calibrated model that says "60% sure" is actually right 60% of the time. |
| **[[1.7.7.5 Probabilistic Language]]** | Nuance | "Likely", "Unlikely", "Rarely", "Often" | Using distinct probabilistic terms helps convey the strength of the evidence. |
| **[[1.7.7.6 Hedging Strategies]]** | Safety | "This might be...", "According to some sources..." | Hedging protects the user from taking the model's word as absolute gospel. |
| **[[1.7.7.7 Epistemic Uncertainty]]** | Knowledge gap | "I lack the data to answer", model ignorance | Uncertainty caused by a lack of knowledge (can be fixed with more data). |
| **[[1.7.7.8 Aleatoric Uncertainty]]** | Randomness | "The outcome is random", inherent noise | Uncertainty caused by the inherent randomness of the world (cannot be fixed). |
| **[[1.7.7.9 Thresholding Answers]]** | Filtering | "If confidence < X, route to human" | Using confidence scores as a switch to decide when to automate and when to escalate. |
| **[[1.7.7.10 Hallucination Indicators]]** | Warning signs | Overconfidence, vague sources, repetitive text | Recognizing the linguistic patterns that often accompany hallucinated facts. |

This table represents a **complete guide to Uncertainty & Confidence**, making AI know what it doesn't know.
