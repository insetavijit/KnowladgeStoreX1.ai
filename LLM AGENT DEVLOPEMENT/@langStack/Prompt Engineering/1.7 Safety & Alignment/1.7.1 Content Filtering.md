# 1.7.1 Content Filtering

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.7.1.1 Keyword Blocking]]** | Basic safety | Blocklists, forbidden words, regex matching | The simplest layer: if the prompt contains word X, block it. fast but brittle. |
| **[[1.7.1.2 Semantic Filtering]]** | Meaning-based | Embeddings, cosine similarity to "harm", classifiers | Detecting harmful concepts (even if they don't use bad words) by comparing the meaning to a forbidden cluster. |
| **[[1.7.1.3 Output Classification]]** | Response check | "Is this safe?", classification model, post-processing | Scanning the *model's response* before showing it to the user to catch slips. |
| **[[1.7.1.4 Policy Enforcement]]** | Rules | Company guidelines, terms of service, AUP | Translating legalese ("No political nuances") into technical filters. |
| **[[1.7.1.5 Handling False Positives]]** | User experience | Appeal process, precision vs recall, blocking "Scunthorpe" | Ensuring the filter doesn't block innocent medical queries or legitimate discussions (the clbuttic problem). |
| **[[1.7.1.6 NSFW Detection]]** | Adult content | Image analysis, text classifiers, age gating | specifically filtering sexual or gore content, often indistinguishable from medical content without context. |
| **[[1.7.1.7 PII Redaction]]** | Privacy | Emails, SSN, Phone numbers, regex scrubbing | Automatically detecting and masking Personal Identifiable Information before it hits the logs or model. |
| **[[1.7.1.8 Hate Speech Filters]]** | Nuance | Protected groups, slur detection, context awareness | Detecting speech that attacks specific groups, requiring high cultural context. |
| **[[1.7.1.9 Moderation APIs]]** | Tools | OpenAI Mod endpoint, Azure Safety, Llama Guard | Leveraging specialized, pre-trained models dedicated solely to safety checking. |
| **[[1.7.1.10 Custom Safety Layers]]** | Architecture | Pre-prompt, Post-prompt, "Shield" model | Adding a dedicated, smaller model just to grade the safety of the input/output. |

This table represents a **complete guide to Content Filtering**, the first line of defense.
