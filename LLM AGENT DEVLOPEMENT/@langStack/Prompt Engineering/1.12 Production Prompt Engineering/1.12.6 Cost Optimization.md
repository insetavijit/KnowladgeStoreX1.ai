# 1.12.6 Cost Optimization

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.12.6.1 Token Counting]]** | Measurement | `tiktoken`, estimation, pre-flight check | Counting tokens *before* you send the request so you know what it will cost. |
| **[[1.12.6.2 Prompt Compression]]** | Reduction | Removing stop words, summarizing context | "Why use many word when few word do trick?" (Kevin Malone strategy). |
| **[[1.12.6.3 Model Downgrading]]** | Selection | GPT-4 -> GPT-3.5, cascade | Automatically switching to a cheaper model for easy queries (saved 90% of cost). |
| **[[1.12.6.4 Fine-tuning ROI]]** | Math | Training cost vs Inference saving | Fine-tuning a small model is expensive upfront but cheaper per-token than querying a giant model. |
| **[[1.12.6.5 Budget Alerts]]** | Control | Daily limits, "Stop the world" switch | Automatically killing the app if it spends more than $100/day (to prevent bankruptcy). |
| **[[1.12.6.6 Per-User Caps]]** | Fair Use | Tiered limits, "Free tier = 10 calls" | preventing one abusive user from burning your entire budget. |
| **[[1.12.6.7 Spot Instances]]** | Infra | Preemptible GPUs, interruptible | Running open-source models on Spot instances (AWS/GCP) for 70% discounts. |
| **[[1.12.6.8 Response Truncation]]** | Limits | `max_tokens`, cutting off runon sentences | Forcing the model to stop after 100 words so it doesn't write a novel on your dime. |
| **[[1.12.6.9 Usage Analytics]]** | Insight | "Which prompt is most expensive?", attribution | Breaking down the bill by feature to see which part of your app is the money sink. |
| **[[1.12.6.10 Vendor Negotiation]]** | Business | Enterprise contracts, reserved capacity | Once you have scale, talking to OpenAI sales for a committed use discount. |

This table represents a **complete guide to Cost Optimization**, keeping the lights on.
