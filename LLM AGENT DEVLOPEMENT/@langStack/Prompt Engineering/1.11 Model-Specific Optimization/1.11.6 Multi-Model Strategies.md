# 1.11.6 Multi-Model Strategies

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.11.6.1 Routing Logic]]** | Architecture | "Router" prompt, classifier | A small model decides: "Is this hard? Send to GPT-4. Is this easy? Send to GPT-3.5." |
| **[[1.11.6.2 Cascade Architecture (Fast -> Slow)]]** | Efficiency | Try cheap model -> If low confidence -> Try expensive model | Failsafe mechanism: Always try the cheapest option first. |
| **[[1.11.6.3 Ensemble Methods (Voting)]]** | Reliability | "Ask 3 models, take majority vote" | Using multiple distinct models to answer and comparing results increases accuracy. |
| **[[1.11.6.4 Fallback Mechanisms]]** | Uptime | "If OpenAI is down, call Anthropic" | Redundancy ensures your app stays online even if one provider crashes. |
| **[[1.11.6.5 Specialization (Writer + Coder)]]** | Roles | "Claude writes the docs, GPT-4 writes the code" | Piping the output of one specialist model into the input of another. |
| **[[1.11.6.6 Consensus Checks]]** | Verification | "Did Model B agree with Model A?" | Using a second model to verify the first model's answer. |
| **[[1.11.6.7 Data Normalization]]** | Pipe | Standardizing outputs across APIs | Dealing with the headache that OpenAI returns JSON one way and Anthropic another. |
| **[[1.11.6.8 Cost Arbitrage]]** | Economics | Dynamic routing based on spot prices | Routing traffic to whoever is cheapest/fastest *right now*. |
| **[[1.11.6.9 Orchestration Frameworks]]** | Tooling | LangChain, Haystack, Semantic Kernel | Libraries designed to manage the complexity of calling multiple models. |
| **[[1.11.6.10 Verification Models]]** | Safety | "Guardrail" model | Using a tiny, fast model solely to check for toxicity before sending to the big model. |

This table represents a **complete guide to Multi-Model Strategies**, building a team instead of a lone wolf.
