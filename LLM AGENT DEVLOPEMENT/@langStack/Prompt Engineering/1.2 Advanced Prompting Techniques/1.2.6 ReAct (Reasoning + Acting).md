# 1.2.6 ReAct (Reasoning + Acting)

| **Section** | **Focus** | **Key Utilities / Concepts** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[1.2.6.1 The ReAct Loop]]** | Agent structure | Thought → Action → Observation, Yao et al. (2022) | Interleaving reasoning ("Thought") with tool use ("Action") allows the model to interact with the world intelligently. |
| **[[1.2.6.2 Tool Use Fundamentals]]** | External capabilities | Search, Calculator, API calls, Database queries | Giving the LLM explicit tools moves it from a text generator to an agent that can fetch facts and perform math. |
| **[[1.2.6.3 Interleaved Reasoning]]** | Dynamic updates | Reason-based action, updating plans based on data | The model reasons about what tool to use, uses it, then reasons about the output to decide the *next* step. |
| **[[1.2.6.4 Handling Observation Data]]** | Input parsing | Truncation, formatting tool outputs, "Observation:" extraction | The "Observation" step feeds the tool's raw output back into the prompt for the model to analyze. |
| **[[1.2.6.5 ReAct vs CoT]]** | Internal vs External | Knowledge retrieval (Action) vs Knowledge recall (Thought) | CoT uses internal training data; ReAct uses external tools to "ground" its reasoning in reality. |
| **[[1.2.6.6 ReAct Failure Modes]]** | Looping & Hallucination | "I need to search" loops, inventing non-existent tools, format errors | Agents often get stuck in loops or hallucinate tool calls; stopping conditions and error handling are critical. |
| **[[1.2.6.7 Formatting ReAct Prompts]]** | Strict syntax | Few-shot traces, stop sequences ("Observation:"), rigid structure | ReAct relies heavily on strict formatting (e.g., `Action: [Search]`) and stop sequences to pause for execution. |
| **[[1.2.6.8 Multi-Step Planning]]** | Horizon management | Sub-goals, task decomposition, memory of previous steps | The model must remember its original goal while navigating through multiple intermediate tool steps. |
| **[[1.2.6.9 Optimizing ReAct]]** | Performance tuning | Fine-tuning for agents (Toolformer), concise traces | Replacing long ReAct prompts with fine-tuned models improves reliability and reduces token costs. |
| **[[1.2.6.10 ReAct in Production (LangChain)]]** | Implementation | LangGraph, AgentExecutor, callbacks, memory persistence | Frameworks like LangChain simplify the orchestration of the Thought-Action-Observation loop in software. |

This table represents a **complete guide to ReAct**, the foundational pattern for building autonomous AI agents.
