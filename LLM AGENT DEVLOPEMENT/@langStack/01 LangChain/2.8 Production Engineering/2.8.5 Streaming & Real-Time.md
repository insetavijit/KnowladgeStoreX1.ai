
| **Subtopic** | **Focus & Purpose** | **Key Concepts / Details** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[2.8.5 Streaming & Real-Time]]** | Latency reduction | showing the answer character-by-character as it generates | Making the AI feel instant. |
| **[[Streaming Callbacks]]** | The mechanism | `on_llm_new_token` callback handler to push updates to UI | The function that runs every time a new word appears. |
| **[[Token Streaming]]** | User Experience | reducing "Time To First Token" (TTFT) perception | Don't make the user stare at a spinning circle. |
| **[[Event Streaming]]** | Structure | streaming intermediate steps (`tool_start`, `tool_end`) | Showing "Thinking..." status updates. |
| **[[SSE (Server-Sent Events)]]** | Transport | using web standard for one-way real-time data flow | The standard way to push stream to browser. |
| **[[WebSockets]]** | Bidirectional | full duplex communication for chat and voice | Real-time chat where both sides talk at once. |
| **[[Real-Time UIs]]** | Integration | handling partial updates in React/Frontend | Updating the text box 50 times a second without flickering. |
