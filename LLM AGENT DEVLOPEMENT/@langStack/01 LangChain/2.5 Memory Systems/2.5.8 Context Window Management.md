
| **Subtopic** | **Focus & Purpose** | **Key Concepts / Details** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[2.5.8 Context Window Management]]** | Optimization | fitting infinite history into finite context windows | Making sure the brain doesn't overflow. |
| **[[Token Counting]]** | Measurement | using `tiktoken` to know exactly how full the context is | Knowing exactly how much space you have left. |
| **[[Message Trimming]]** | Pruning | removing oldest messages when limit is reached | Cutting off the tail of the conversation to save the head. |
| **[[Summarization]]** | Compression | converting 100 messages into 1 summary paragraph | Turning a book into a blurb to save space. |
| **[[Context Compression]]** | RAG optimization | using `ContextualCompressionRetriever` to shrink docs | Squeezing document chunks before giving them to the LLM. |
| **[[Cost Optimization]]** | Budgeting | managing context to stay within API billing limits | Saving money by sending fewer tokens. |
| **[[Preventing Context Overflow]]** | Error handling | logic to ensure request never exceeds model max tokens | Stopping the "Model Capacity Exceeded" error before it happens. |
