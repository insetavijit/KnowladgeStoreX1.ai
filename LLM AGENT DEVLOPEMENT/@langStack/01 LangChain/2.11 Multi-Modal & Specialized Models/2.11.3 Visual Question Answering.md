
| **Subtopic** | **Focus & Purpose** | **Key Concepts / Details** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[2.11.3 Visual Question Answering]]** | Interaction | asking questions about the content of an image | "Is the light red or green?" |
| **[[VQA Chains]]** | Structure | specialized chains designed for Image + Question = Answer | The standard pattern for talking to pictures. |
| **[[Image-Text Retrieval]]** | Search | finding images that match a text query | "Show me all photos of 'happy dogs'." |
| **[[Visual Grounding]]** | Verification | locating the answer in the image (e.g., coordinates) | "The answer is here, at [x,y]." |
| **[[Multi-Modal RAG]]** | Context | retrieving both text documents and images to answer a query | Reading the manual AND looking at the diagram. |
| **[[Image Search]]** | Discovery | using CLIP embeddings to search image databases with text | Searching visuals with words. |
| **[[Vision-Based QA]]** | Application | building chatbots that can debug screen captures | "Upload your screenshot and I'll tell you what's wrong." |
