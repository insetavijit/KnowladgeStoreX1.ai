| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.4.7 Embedding Extraction Overview]]**| Retrieve internal vector representations from models           | hidden states, output heads, pre-logits, transfer learning setup                           | Getting the numbers out of the black box to use elsewhere.             |
| **[[HuggingFace Transformers]]**        | The standard library for extraction                            | `model(inputs, output_hidden_states=True)`, accessing `outputs.hidden_states`              | HuggingFace makes it a one-line toggle to get all internal layers.     |
| **[[Layer Selection Strategy]]**        | Choosing the right layer for the task                          | first layer (phrase-level), middle (syntactic), last (semantic/task-specific)              | Don't just take the last layer; the middle layers often hold better general features.|
| **[[Aggregation Strategies]]**          | Combining subword tokens into word/sentence vectors            | mean-over-time, max-over-time, first-token (CLS), handling subword splits (mean of parts)  | Reassembling the shattered subwords back into whole concepts.          |
| **[[Batch Processing]]**                | Efficiently extracting massive datasets                        | `DataLoader`, GPU max batch size, avoiding OOM (Out Of Memory), padding management         | Extraction is slow unless you process thousands of sentences at once.  |
| **[[Efficient Storage]]**               | Saving extracted embeddings                                    | Numpy `.npy`, HDF5, Faiss indexes, avoiding CSV for vector data                            | Vectors act like heavy liquids; store them in optimized binary containers.|
