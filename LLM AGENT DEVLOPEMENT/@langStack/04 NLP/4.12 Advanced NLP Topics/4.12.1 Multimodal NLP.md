| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.12.1 Multimodal NLP Overview]]**  | Combining text with other senses                               | Vision-Language, Audio-Text, unifying modalities in a single model                         | "A picture is worth a thousand words," and AI now understands both.    |
| **[[CLIP (Contrastive Language-Image Pre-training)]]**| Connecting text and images                         | Alignment of image and text vectors in shared space, zero-shot classification              | Knowing that a photo of a dog matches the text "A photo of a dog".     |
| **[[VQA (Visual Question Answering)]]** | Answering questions about images                               | "What color is the shirt?", processing image features and question features together       | Looking at a picture to answer "Is it raining?".                       |
| **[[Image Captioning]]**                | Describing images                                              | Encoder (CNN/ViT) -> Decoder (LSTM/Transformer), translating pixels into sentences         | Generating "A cat sitting on a sofa" from a JPEG.                      |
| **[[Multimodal Transformers]]**         | Unified architectures                                          | ViLLM, Flamingo, GPT-4V, processing interleaved text and image inputs                      | Reading a textbook that has diagrams in it.                            |
| **[[Audio-Text (ASR & TTS)]]**          | Listening and Speaking                                         | Whisper (ASR), SpeechT5, bridging the gap between sound waves and tokens                   | Giving the AI ears and a mouth.                                        |
