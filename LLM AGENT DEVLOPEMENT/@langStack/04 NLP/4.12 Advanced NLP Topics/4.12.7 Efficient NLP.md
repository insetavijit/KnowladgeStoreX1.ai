| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.12.7 Efficient NLP Overview]]**   | Making models faster and smaller                               | Reducing latency, memory footprint, and energy consumption, Edge AI                        | Putting an elephant in a Mini Cooper.                                  |
| **[[Knowledge Distillation]]**          | Teacher -> Student training                                    | Training a small model (student) to mimic the logits of a large model (teacher)            | The master teaching the apprentice everything they know.                 |
| **[[Quantization]]**                    | Reducing precision                                             | FP32 -> FP16 -> INT8 -> INT4, Post-Training Quantization (PTQ), Quantization-Aware Training| Storing numbers with fewer decimal places to save space.               |
| **[[Pruning]]**                         | Removing weights                                               | Structured pruning (removing whole heads/layers), Unstructured pruning (setting weights to 0)| Trimming the dead leaves off the tree so it grows better.              |
| **[[Efficient Attention]]**             | Linear complexity attention                                    | Sparse attention, Linformer, Performer, approximating the N^2 attention matrix             | Looking at a summary of the room instead of staring at every person.   |
| **[[Early Exit]]**                      | Dynamic computation                                            | Allowing the model to output an answer at layer 4 if it's confident, skipping layers 5-12  | Stopping the test as soon as you pass, instead of answering every question.|
