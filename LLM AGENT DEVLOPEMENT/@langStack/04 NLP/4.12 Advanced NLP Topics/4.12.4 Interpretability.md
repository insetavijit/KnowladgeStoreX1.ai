| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.12.4 Interpretability Overview]]**| Understanding why the model thought that                       | Black box problem, trust, debugging, legal requirements (Right to Explanation)             | Opening the hood to see why the engine is making that noise.           |
| **[[Attention Visualization]]**         | Looking at weights                                             | Heatmaps, BertViz, showing which words the model focused on (Warning: Attention != Explanation)| "It looked at the word 'Dog' when it predicted 'Bark'."                |
| **[[LIME / SHAP]]**                     | Feature importance                                             | Local Interpretable Model-agnostic Explanations, perturbing input to see output changes    | "If I delete the word 'not', the sentiment flips, so 'not' was important."|
| **[[Saliency Maps]]**                   | Gradient-based explanation                                     | Integrated Gradients, visualizing which pixels/tokens contributed most to the loss         | Highlighting the exact text that triggered the detector.               |
| **[[Probing Classifiers]]**             | Checking internal knowledge                                    | Training small classifiers on hidden states to see if they encode syntax/pos/entailment    | Checking if layer 3 knows what a verb is.                              |
| **[[Counterfactual Explanations]]**     | "What if?" analysis                                            | Generating minimal edits to flip the prediction                                            | "The loan was denied. If your income was $1k higher, it would have been approved."|
