| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.12.5 Bias & Fairness Overview]]** | Preventing harm                                                | Allocational harm (hiring), Representational harm (stereotypes), toxicity                  | Ensuring the AI isn't racist or sexist.                                |
| **[[Bias in Embeddings]]**              | Geometric bias                                                 | "Man is to Computer Programmer as Woman is to Homemaker", removing gender/race vector components| Fixing the math so "Doctor" isn't closer to "Man" than "Woman".        |
| **[[Data Bias]]**                       | The source of the problem                                      | Over-representation of Western views, under-representation of minorities, historical stereotypes in text| If the textbooks are biased, the student will be too.                  |
| **[[Debiasing Techniques]]**            | Fixing the model                                               | Counterfactual Data Augmentation (CDA), Projection Pursuit, Adversarial Training           | Swapping "He" for "She" in training data to balance the scales.        |
| **[[Fairness Metrics]]**                | Measuring equality                                             | Demographic Parity, Equalized Odds, ensuring error rates are similar across groups         | Checking if the model is equally wrong for everyone.                   |
| **[[Toxicity Detection]]**              | Content moderation                                             | Identifying hate speech, profanity, and harassment, preventing the chatbot from swearing   | The bouncer at the club keeping the conversation civil.                |
