| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.3.8 Bias in Embeddings Overview]]**| Identify and mitigate societal biases in vectors               | gender bias, racial bias, stereotyping, historical data reflection                         | Models learn the prejudice hidden in the training data.                |
| **[[Detecting Bias]]**                  | Measuring association differences                              | WEAT (Word Embedding Association Test), distance to sensitive attributes (He/She)          | Does "Doctor" cluster closer to "He" and "Nurse" to "She"?             |
| **[[Sources of Bias]]**                 | Where the bias comes from                                      | training corpus (Common Crawl, Wikipedia), selection bias, frequency bias                  | If the internet says it, the model learns itâ€”warts and all.            |
| **[[Debiasing Techniques]]**            | Algorithms to remove bias                                      | Hard Debiasing (projecting away gender direction), Soft Debiasing, GN-GloVe                | Mathematically removing the "gender component" from neutral words.     |
| **[[Lipstick on a Pig]]**               | Critique of debiasing                                          | superficial removal vs deep clustering retention, residual bias                            | You can hide the bias vector, but the clusters might still remain.     |
| **[[Fairness Metrics]]**                | Quantifying success in debiasing                               | equalizing proximity, reducing association score gaps, downstream fairness                 | Numbers to prove we aren't just guessing if it's better.               |
