| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.9.6 Text Generation Overview]]**  | Turning probabilities into text                                | Decoding strategies, addressing repetition, controlling creativity                         | Choosing which word to actually write down.                            |
| **[[Greedy Decoding]]**                 | Picking the most likely word                                   | Argmax, boring output, repetitive loops, often gets stuck                                  | Always picking the safest option, resulting in a dull story.           |
| **[[Beam Search]]**                     | Exploring multiple paths                                       | Keeping Top-K incomplete sentences (beams), finding the best overall sequence              | Looking 5 moves ahead in chess before making a move.                   |
| **[[Temperature Sampling]]**            | Controlling randomness                                         | High temp = creative/random, Low temp = focused/deterministic, scaling logits              | Turning up the "Crazy Knob" on the writer.                             |
| **[[Top-K & Top-P (Nucleus)]]**         | Truncating the tail                                            | Top-K: Pick from top 50 words; Top-P: Pick from top cumulative 90% probability             | Ignoring the weird, unlikely words to keep the story coherent.         |
| **[[Repetition Penalty]]**              | Fixing loops                                                   | Penalizing tokens that have already appeared, forcing diversity                            | Banning the model from saying "and then" 50 times in a row.            |
