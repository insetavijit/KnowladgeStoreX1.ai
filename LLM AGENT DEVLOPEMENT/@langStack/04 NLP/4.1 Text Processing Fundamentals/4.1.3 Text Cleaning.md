| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.1.3 Text Cleaning Overview]]**    | Remove noise and irrelevant information                        | signal-to-noise ratio, garbage in garbage out, preprocessing efficiency                    | Text cleaning strips away non-semantic elements to reveal the core message. |
| **[[HTML Stripping]]**                  | Remove markup tags and decode entities                         | BeautifulSoup, regex tag removal, handling `&nbsp;`, `&amp;`, preserving structure vs raw text | Models read text, not markup; stripping exposes the human-readable content. |
| **[[Special Character Handling]]**      | Manage non-alphanumeric symbols and artifacts                  | emoji filtering, currency symbols, hashtags, removing invisible control characters         | Special characters are either semantic signals or noise depending on the task. |
| **[[Whitespace Normalization]]**         | Standardize spacing and layout                                 | trimming, collapsing multiple spaces, handling tabs/newlines, zero-width spaces            | Consistent spacing prevents tokenizer fragmentation and alignment issues.   |
| **[[Removing Noise]]**                  | Filter out low-information text blocks                         | header/footer removal, disclaimer stripping, boilerplate code, removing URLs               | Noise removal focuses the model on the actual content, not the container.   |
| **[[Data Quality]]**                    | Ensure text integrity and validity                             | language detection, minimum length checks, gibberish filtering, duplicate handling         | High-quality models require high-quality, valid, and unique data points.    |
| **[[Cleaning Pipelines]]**              | Automate and chain cleaning steps                              | sequential processing, reproducibility, custom regex rules, order of operations            | Pipelines turn raw, messy scrapes into structured, usable datasets.         |
