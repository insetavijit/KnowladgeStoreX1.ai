| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.6.2 POS Tagging Methods Overview]]**| Algorithms to assign tags to sequences                         | rule-based, stochastic (HMM), feature-based (CRF), neural (BiLSTM/BERT)                    | From "words ending in -ed are verbs" to complex probability models.    |
| **[[HMM Tagging]]**                     | Hidden Markov Model approach                                   | transition probabilities (tag -> tag), emission probabilities (tag -> word), Viterbi algo  | Predicting the hidden grammar state based on the visible word output.  |
| **[[CRF Tagging]]**                     | Conditional Random Fields for tagging                          | discriminative modeling, rich features (capitalization, prefix/suffix), global optimization| Improving on HMMs by looking at the whole sentence's features at once. |
| **[[Neural Tagging]]**                  | Deep learning for POS                                          | Embedding layers, BiLSTM context, softmax output, end-to-end learning                      | Letting the network learn the grammar rules from raw text.             |
| **[[BERT POS Tagging]]**                | Using Transformers for tagging                                 | fine-tuning, subword handling, handling complex context and dependencies                   | The sledgehammer approach: using a giant brain for a basic task.       |
| **[[NLTK / SpaCy]]**                    | Library implementations                                        | `nltk.pos_tag` (Preceptron), `nlp()` (statistical/neural), ease vs control                 | One line of code to get state-of-the-art tags.                         |
