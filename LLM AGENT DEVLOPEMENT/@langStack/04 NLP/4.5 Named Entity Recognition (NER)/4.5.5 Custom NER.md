| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.5.5 Custom NER Overview]]**       | Train models for entities not in standard datasets             | domain adaptation, "Ingredient" tags, "Part Number" tags, specific business logic          | When "Person" and "Location" aren't enough, you build your own.        |
| **[[Annotation]]**                      | Identifying and labeling entities in your text                 | span highlighting, consistency, handling ambiguity, creating the gold standard             | Good models start with good human labeling.                            |
| **[[Prodigy / Label Studio]]**          | Tools for efficient data labeling                              | active learning, easy interfaces, reviewing predictions, resolving conflicts                | Don't use Excel; use a tool that learns while you click.               |
| **[[Active Learning]]**                 | Improving the model with the minimum number of labels          | sampling uncertain examples, "human in the loop", iterative training cycles                | Labeling only the examples that confuse the model the most.            |
| **[[Training Custom Models]]**          | The process of teaching the tokenizer/model                    | `nlp.update` (SpaCy), fine-tuning HuggingFace models, preventing catastrophic forgetting   | Fine-tuning a pre-trained base on your tiny, specialized dataset.      |
| **[[Data Augmentation]]**               | artificially increasing the training set                       | synonym replacement, entity swapping, generating usage patterns, weak supervision          | Creating more training data by remixing what you already have.         |
