| **Subtopic**                            | **Focus & Purpose**                                            | **Key Concepts / Details**                                                                 | **One-Line Recall**                                                    |
| --------------------------------------- | -------------------------------------------------------------- | ------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------- |
| **[[4.7.4 Neural Classifiers Overview]]**| Deep learning for text/sequence classification                 | Non-linear relationships, learned embeddings, end-to-end training                          | Brain-inspired networks that learn features automatically.             |
| **[[Word Embeddings Input]]**           | Representing words as dense vectors                            | Word2Vec, GloVe, learnable embedding layers, handling semantic similarity                  | Feeding definitions instead of just word counts.                       |
| **[[CNN for Text]]**                    | Detecting local patterns                                       | 1D Convolutions, max-pooling, detecting n-gram features (phrases) anywhere in text         | Scanning for key phrases like a sliding window.                        |
| **[[RNN / LSTM / GRU]]**                | Modeling sequence and order                                    | Sequential processing, hidden states, handling long-term dependencies, vanishing gradient  | Reading the sentence from left to right and remembering the context.   |
| **[[Bi-Directional LSTM]]**             | Reading both ways                                              | Forward and Backward passes, concatenating states, full context visibility                 | Reading the sentence forward and backward to understand it fully.      |
| **[[Attention Mechanisms]]**            | Focusing on what matters                                       | Self-attention, weighting input words, interpreting model decisions                        | Highlighting the important words in yellow marker.                     |
