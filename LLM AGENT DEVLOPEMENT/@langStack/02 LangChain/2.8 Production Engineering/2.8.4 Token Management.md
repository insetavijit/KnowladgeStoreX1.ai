
| **Subtopic** | **Focus & Purpose** | **Key Concepts / Details** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[2.8.4 Token Management]]** | Cost & Capacity | managing finite token budgets and context windows | Keeping track of your word count and bill at the same time. |
| **[[Token Counting]]** | Measurement | using `tiktoken` to calculate exact token usage before sending | Knowing exactly how much a request will cost. |
| **[[Context Window Limits]]** | Boundaries | logic to truncate or summarize inputs that exceed 8k/32k/128k limits | Fitting the elephant into the fridge. |
| **[[Token Optimization]]** | Efficiency | using shorter prompts, removing fluff to save space | Say more with less. |
| **[[Cost Tracking]]** | Analytics | `callbacks.OpenAICallback` to track spend per request | Auditing "Who spent $50 on GPT-4 today?" |
| **[[Budget Enforcement]]** | Control | setting hard limits on daily spend or per-user usage | Stopping the meter before it runs too high. |
| **[[Model Selection]]** | Strategy | switching between models based on needed context length | using GPT-4-32k only when 8k isn't enough. |
