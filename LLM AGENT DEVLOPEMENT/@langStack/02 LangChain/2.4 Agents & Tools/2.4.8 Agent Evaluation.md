
| **Subtopic** | **Focus & Purpose** | **Key Concepts / Details** | **One-Line Recall** |
| :--- | :--- | :--- | :--- |
| **[[2.4.8 Agent Evaluation]]** | Measuring autonomy | trajectory analysis, tool usage correctness, goal completion | Checking if the agent is actually smart or just lucky. |
| **[[Trajectory Evaluation]]** | Reviewing the path | did the agent take the optimal steps to solve the problem? | Grading the thought process, not just the answer. |
| **[[Tool Usage Accuracy]]** | Validating actions | did the agent call the tool with correct arguments? | Checking if the agent knows how to use its hands. |
| **[[Goal Completion Rate]]** | Success metrics | percentage of tasks successfully finished | How often the agent actually wins. |
| **[[Harmlessness]]** | Safety checks | ensuring agent doesn't take dangerous actions | Making sure the agent doesn't delete your database. |
| **[[LangSmith Evaluation]]** | Automated grading | using `evaluators="trajectory"`, comparing against dataset | Using a robot to grade the robot. |
| **[[Human-in-the-loop]]** | Manual review | `human_approval` step before sensitive actions | Letting a human say "yes" before the agent pushes the big red button. |
