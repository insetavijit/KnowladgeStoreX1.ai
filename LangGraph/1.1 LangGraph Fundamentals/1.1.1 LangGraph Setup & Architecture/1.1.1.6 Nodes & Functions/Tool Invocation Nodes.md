# Tool Invocation Nodes

**Core Definition:** Nodes responsible for executing external functions (Tools) requested by the model.

## The Standard Pattern
1.  **LLM Node:** Generates a message containing `tool_calls`.
2.  **Tools Node:**
    -   Scans the last message.
    -   If `tool_calls` exist, executes the corresponding functions.
    -   Returns a `ToolMessage` with the output.

## Using `ToolNode` (Built-in)
LangGraph provides a pre-built node for this common pattern.

```python
from langgraph.prebuilt import ToolNode
from src.tools import tools

tool_node = ToolNode(tools)
workflow.add_node("tools", tool_node)
```

## Custom Tool Nodes
Sometimes you need more control (e.g., "Human approval before tool execution").

```python
def custom_tool_node(state):
    last_msg = state["messages"][-1]
    results = []
    
    for call in last_msg.tool_calls:
        if call["name"] == "dangerous_tool":
            # Add custom logic here
            pass
        
        # Execute
        result = my_tool_executor(call)
        results.append(ToolMessage(tool_call_id=call["id"], content=result))
        
    return {"messages": results}
```

## Error Handling
Tools often fail (API down, bad args).
-   **Always catch exceptions** inside the tool node.
-   Return a `ToolMessage` with the error text so the LLM can try to fix it.

## Quick Summary

**1-Line Recall:** **Tool Nodes are the "hands" of the agent; they execute the `tool_calls` generated by the LLM and report back `ToolMessages`.**
