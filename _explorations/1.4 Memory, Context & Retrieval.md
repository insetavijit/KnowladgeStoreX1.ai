## 1.4 Memory, Context & Retrieval — How agents store, compress, and retrieve knowledge over time

Agent memory systems extend the limited context window of LLMs, allowing agents to retain information across interactions, learn from experience, and access vast external knowledge bases. This enables stateful behavior, personalization, and grounded responses in single- and multi-agent setups.

### 1.4.1 Memory Types & Hierarchy — Different kinds of memory and when to use each

Agent memory draws inspiration from human cognition, implementing layered storage for different timescales and purposes.

- **Short-term memory** — Current session context in the prompt window: Fast access, limited by token count.
- **Long-term memory** — Persistent memory across sessions: External storage for continuity.
- **Semantic memory** — Facts and structured knowledge base: Declarative knowledge (e.g., "Paris is the capital of France").
- **Episodic memory** — Past interactions and experiences: Specific events and conversations.
- **Working memory** — Temporary scratchpad for reasoning: Active manipulation during task execution.
- **Memory hierarchy** — Which memory to consult first and why: Prioritize short-term → working → long-term for efficiency.
- **When to use each** — Map memory type to task needs: Short-term for ongoing dialogue; episodic for personalization; semantic for factual recall.
- **Memory lifecycle** — Create, update, consolidate, forget: Full management pipeline for relevance and efficiency.

### 1.4.2 Context Window Management & Compression — Working within token limits efficiently

As context windows grow (128K–1M+ tokens in 2025 models), efficient management remains essential for cost, latency, and focus.

- **Token limits** — Model-specific caps (128K, 200K, 1M, etc.): Define maximum working context.
- **Summarization strategies** — Extractive vs abstractive vs progressive: Reduce history while preserving key information.
- **Context compression** — Shrink history while preserving meaning: Techniques like LLM-based distillation.
- **Sliding window** — Keep most recent turns only: Simple recency bias.
- **Context retention** — Score by recency, relevance, importance: Intelligent pruning.
- **Conversation summaries** — Replace long history with synopsis: Maintain continuity with minimal tokens.
- **External memory trigger** — Move old context to vector store: Offload when window nears limit.
- **Cost optimization** — Fewer tokens, lower spend: Critical for production systems.

### 1.4.3 Vector Databases & RAG Implementation — Retrieving knowledge at scale

RAG remains the dominant pattern for grounding agents in external or private knowledge, combining retrieval with generation.

- **Embeddings** — Convert text to vectors for semantic search: Dense representations (e.g., from OpenAI, Cohere, or open models).
- **Vector DBs** — Pinecone, Weaviate, Chroma, FAISS, etc.: Scalable similarity search backends.
- **RAG pattern** — Retrieve → augment prompt → generate: Standard flow for factual grounding.
- **Chunking strategies** — Sentence, paragraph, semantic, recursive: Optimize retrieval units.
- **Hybrid search** — Keyword + semantic retrieval: Combines BM25 with vector similarity.
- **Re-ranking** — Order results by relevance: Cross-encoders or LLM-based scorers.
- **Retrieval metrics** — Precision, recall, MRR: Evaluate system performance.
- **RAG vs fine-tuning** — Knowledge vs behavior changes: RAG for dynamic facts; fine-tuning for style/skills.
- **Agent memory with vectors** — Use stores as long-term memory: Persistent episodic/semantic storage.
- **RAG evaluation** — Measure grounding and answer quality: Tools like RAGAS, ARES.

### 1.4.4 Shared Memory in Multi-Agent Systems — Coordinating knowledge across agents

In multi-agent setups, memory coordination enables collaboration, consistency, and collective intelligence.

- **Shared memory architectures** — Central store for all agents: Unified view of state.
- **Isolation vs sharing** — Private vs common memory trade-offs: Privacy/scalability vs coordination.
- **Consistency challenges** — Conflicting reads/writes: Race conditions in concurrent access.
- **Synchronization patterns** — Locks, versions, timestamps: Ensure orderly updates.
- **Blackboard pattern** — Agents post/read shared facts: Classic collaborative model.
- **Distributed memory** — Partitioned across nodes: For large-scale systems.
- **Access control** — Permissions per agent/role: Security and role alignment.
- **Conflict resolution** — Merge or override strategies: Handle contradictory updates.
- **Eventual consistency** — Accept temporary divergence: Prioritize availability over strict sync.
- **Memory sharding** — Split memory for scale: Horizontal partitioning.

### 1.4.5 Semantic Memory Implementation — Building durable agent knowledge

Long-term, structured knowledge enables agents to accumulate expertise over time.

- **Knowledge bases** — Store structured facts: Triple stores or document databases.
- **Entity extraction & linking** — Identify people, places, concepts: NER and disambiguation.
- **Fact verification** — Validate before storing: Reduce hallucination propagation.
- **Knowledge graphs** — Neo4j, NetworkX integrations: Relational reasoning.
- **Retrieval strategies** — Similarity, recency, importance: Multi-factor scoring.
- **Memory updates & versioning** — Track changes over time: Audit trails.
- **Forgetting strategies** — Decay or prune low-value memories: Prevent bloat.
- **Memory consolidation** — Summarize episodes into facts: Convert experiences to declarative knowledge.

If you want, Boss, I can also:

* create a condensed interview cheat sheet for 1.4, or
* add a memory-type comparison table, or
* integrate 1.4 into your full LLM Agent master outline.